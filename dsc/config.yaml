DSC:
  midway2:
    description: UChicago RCC cluster Midway 2
    address: localhost
    paths:
      home: /home/joycehsiao
    queue_type: pbs
    status_check_interval: 60
    max_running_jobs: 40
    max_cores: 40
    max_walltime: "36:00:00"
    max_mem: 64G
    job_template: |
      #!/bin/bash
      #SBATCH --time={walltime}
      #{partition}
      #{account}
      #SBATCH --nodes=1
      #SBATCH --ntasks-per-node={cores}
      #SBATCH --mem-per-cpu={mem//10**9}G
      #SBATCH --job-name={job_name}
      #SBATCH --output={cur_dir}/.sos/{job_name}.stdout
      #SBATCH --error={cur_dir}/.sos/{job_name}.stderr
      cd {cur_dir}
      module load R/3.5.1
    partition: "SBATCH --partition=broadwl"
    account: "SBATCH --partition=mstephens"
    submit_cmd: sbatch {job_file}
    submit_cmd_output: "Submitted batch job {job_id}"
    status_cmd: squeue --job {job_id}
    kill_cmd: scancel {job_id}
  faraway2:
    based_on: midway2
    description: Submit and manage jobs to `midway2` from a local computer.
    address: joycehsiao@midway2.rcc.uchicago.edu
  stephenslab:
    based_on: midway2
    max_cores: 28
    max_mem: 128G
    max_walltime: "10d"
    partition: "SBATCH --partition=mstephens"
    account: "SBATCH --account=pi-mstephens"
  giladlab:
    based_on: midway2
    max_cores: 28
    max_mem: 128G
    max_walltime: "10d"
    partition: "SBATCH --partition=gilad"
    account: "SBATCH --account=pi-gilad"

default:
  queue: giladlab
  time_per_instance: 2m
  instances_per_job: 1
  n_cpu: 2
  mem_per_cpu: 4G

# module specific configurations
# mostly to consolidate small jobs
get_data:
  instances_per_job: 20
method:
  time_per_instance: 6m
  instances_per_job: 20
