ub <- unique(block)
nblocks <- length(ub)
Z <- matrix(block, narrays, nblocks) == matrix(ub, narrays,
nblocks, byrow = TRUE)
cormatrix <- Z %*% (correlation * t(Z))
}
diag(cormatrix) <- 1
ngenes <- nrow(M)
stdev.unscaled <- matrix(NA, ngenes, nbeta,
dimnames = list(rownames(M),
coef.names))
# NoProbeWts <- all(is.finite(M)) && (is.null(weights) || !is.null(attr(weights,
#                                                                      "arrayweights")))
#     if (NoProbeWts) {
#         V <- cormatrix
#         if (!is.null(weights)) {
#             wrs <- 1/sqrt(weights[1, ])
#             V <- wrs * t(wrs * t(V))
#         }
#         cholV <- chol(V)
#         y <- backsolve(cholV, t(M), transpose = TRUE)
#         dimnames(y) <- rev(dimnames(M))
#         X <- backsolve(cholV, design, transpose = TRUE)
#         dimnames(X) <- dimnames(design)
#         fit <- lm.fit(X, y)
#         if (fit$df.residual > 0) {
#             if (is.matrix(fit$effects))
#                 fit$sigma <- sqrt(colMeans(fit$effects[-(1:fit$rank),
#                                                        , drop = FALSE]^2))
#             else fit$sigma <- sqrt(mean(fit$effects[-(1:fit$rank)]^2))
#         }
#         else fit$sigma <- rep(NA, ngenes)
#         fit$fitted.values <- fit$residuals <- fit$effects <- NULL
#         fit$coefficients <- t(fit$coefficients)
#         fit$cov.coefficients <- chol2inv(fit$qr$qr, size = fit$qr$rank)
#         est <- fit$qr$pivot[1:fit$qr$rank]
#         dimnames(fit$cov.coefficients) <- list(coef.names[est],
#                                                coef.names[est])
#         stdev.unscaled[, est] <- matrix(sqrt(diag(fit$cov.coefficients)),
#                                         ngenes, fit$qr$rank, byrow = TRUE)
#         fit$stdev.unscaled <- stdev.unscaled
#         fit$df.residual <- rep.int(fit$df.residual, ngenes)
#         dimnames(fit$stdev.unscaled) <- dimnames(fit$stdev.unscaled) <- dimnames(fit$coefficients)
#         fit$pivot <- fit$qr$pivot
#         fit$ndups <- ndups
#         fit$spacing <- spacing
#         fit$block <- block
#         fit$correlation <- correlation
#         return(fit)
#     }
beta <- stdev.unscaled
sigma <- rep(NA, ngenes)
df.residual <- rep(0, ngenes)
for (i in 1:ngenes) {
design_gene <- cbind(design, unlist(cov_matrix[i,]))
y <- drop(M[i, ])
o <- is.finite(y)
y <- y[o]
n <- length(y)
if (n > 0) {
X <- design_gene[o, , drop = FALSE]
V <- cormatrix[o, o]
if (!is.null(weights)) {
wrs <- 1/sqrt(drop(weights[i, o]))
V <- wrs * t(wrs * t(V))
}
cholV <- chol(V)
y <- backsolve(cholV, y, transpose = TRUE)
if (all(X == 0)) {
df.residual[i] <- n
sigma[i] <- sqrt(array(1/n, c(1, n)) %*% y^2)
}
else {
X <- backsolve(cholV, X, transpose = TRUE)
out <- lm.fit(X, y)
est <- !is.na(out$coefficients)
beta[i, ] <- out$coefficients
stdev.unscaled[i, est] <- sqrt(diag(chol2inv(out$qr$qr,
size = out$rank)))
df.residual[i] <- out$df.residual
if (df.residual[i] > 0)
sigma[i] <- sqrt(array(1/out$df.residual, c(1,
n)) %*% out$residuals^2)
}
}
}
cholV <- chol(cormatrix)
QR <- qr(backsolve(cholV, design_gene, transpose = TRUE))
cov.coef <- chol2inv(QR$qr, size = QR$rank)
est <- QR$pivot[1:QR$rank]
dimnames(cov.coef) <- list(coef.names[est], coef.names[est])
list(coefficients = beta, stdev.unscaled = stdev.unscaled,
sigma = sigma, df.residual = df.residual, ndups = ndups,
spacing = spacing, block = block, correlation = correlation,
cov.coefficients = cov.coef, pivot = QR$pivot, rank = QR$rank,
design = design)
}
### voom_general
voom_general  <- function (counts, cov_matrix,
span = 0.5, plot = FALSE)
{
design <- matrix(1, ncol(counts), 1)
rownames(design) <- colnames(counts)
colnames(design) <- "GrandMean"
fit <- lmFit(counts, design)
sx <- log10(rowMeans(cov_matrix, na.rm = TRUE) + 1)
sy <- sqrt(fit$sigma)
df <- cbind(sx,sy)
df <- df[rowSums(is.na(df)) == 0, ]
l <- lowess(df, f = .5)
if (plot) {
plot(df, xlab = "log10 meausrement",
ylab = "Sqrt( standard deviation )",
pch = 16, cex = 0.25)
title("voom: Mean-variance trend")
lines(l, col = "red")
}
f <- approxfun(l, rule = 2)
#fitted.values <- fit$coef %*% t(fit$design)
w <- 1/f(as.matrix(cov_matrix))^4
dim(w) <- dim(cov_matrix)
return(w)
}
### PREPARE DATA
colnames(GelPrep) <- c("HL18862", "HL18486", "HL19160")
PhosProtGel <- merge(phosdata, GelPrep, by = "row.names",
suffixes = c("_peptide", "_GelPrep") ) #3257 observations
rownames(PhosProtGel) <- PhosProtGel$Row.names
PhosProtGel <- PhosProtGel[ , -1]
PhosProtGel <- as.matrix(PhosProtGel)
### Make meta data matrix
sampleLabels <- strsplit( colnames(PhosProtGel)[1:12], split = "_", fixed = FALSE)
metaData <- data.frame(individual = as.factor(sapply(sampleLabels, "[[", 1)),
biorep = as.factor(sapply(sampleLabels, "[[", 2)),
techrep = as.factor(sapply(sampleLabels, "[[", 3)) )
metaData <- rbind(metaData,
data.frame(individual = colnames(PhosProtGel)[13:15],
biorep = "NA",
techrep = "NA") )
metaData$dataType <- c(rep("peptide", 12), rep("GelPrep", 3) )
metaData$label <- with(metaData, paste(individual, biorep, techrep, sep = "_"))
### FIT A LINEAR MODEL FOR ONE PEPTIDE AT A TIME
# First, add random perturbation to the covariate matrix
ii_phosprotgel <- metaData$dataType == "GelPrep"
randomPhosProtGel <- PhosProtGel[ , ii_phosprotgel] +
matrix( runif(NROW(PhosProtGel[ , ii_phosprotgel])*NCOL(PhosProtGel[ , ii_phosprotgel]),
0, 10^(-6)),
nrow(PhosProtGel[ , ii_phosprotgel]) )
ii_peptide <- metaData$dataType == "peptide"
metaData_peptide <- metaData[ ii_peptide, ]
order_phosgel <- match(metaData_peptide$individual, colnames(randomPhosProtGel) )
randomPhosProtGel <- randomPhosProtGel[, order_phosgel]
# Compute correlation due to the random effect of
# biological replicate
corrsPhosProtGel <- sapply(1:nrow(PhosProtGel), function(per_peptide) {
# Make a data matrix for peptide i information
per_phenoData <- cbind(metaData[ metaData$dataType == "peptide", ],
peptide = PhosProtGel[per_peptide, metaData$dataType == "peptide"],
phosgel = randomPhosProtGel[per_peptide, ])
designMatrix <- model.matrix(~ 0 + individual + phosgel,
data = per_phenoData)
block <- per_phenoData$biorep
yy <- per_phenoData$peptide
mixedModel2Fit_multiple_design(design = designMatrix, block = block, yy = yy)
})
corrsPhosProtGel_mean <- mean(corrsPhosProtGel)
# Per gene limma mixed model
designMatrix <- model.matrix(~ 0 + individual, data = metaData_peptide )
intensity_matrix <- data.frame(
id = MultExpanded1$idmult,
MultExpanded1[ ,grep("Intensity.1", colnames(MultExpanded1))])
ii_phosdata <- match(rownames(PhosProtGel), intensity_matrix$id)
intensity_phosdata <- intensity_matrix[ii_phosdata, ]
weights_phosdata <- voom_general(counts = PhosProtGel[ , ii_peptide],
cov_matrix = intensity_phosdata[,c(2:13)],
plot = TRUE)
glsRes <- gls.series_multiple_designs(M = PhosProtGel[ ,ii_peptide ],
cov_matrix = randomPhosProtGel,
design = designMatrix,
ndups = 1,
spacing = 1,
block = metaData[ ii_peptide, ]$biorep,
correlation = corrsPhosProtGel_mean,
weights = weights_phosdata)
# Contrast test
designMatrixCov <- model.matrix(~ 0 + individual + pseudoCov,
data = data.frame(metaData_peptide, pseudoCov = runif(12) ) )
contrastMatrix <- makeContrasts(individualHL18862 - individualHL18486, individualHL19160 - individualHL18862,
individualHL19160 - individualHL18486,
levels = designMatrixCov)
rownames(contrastMatrix) <- colnames(glsRes$coefficients)
fit2 <- contrasts.fit(glsRes, contrastMatrix)
GelPrepCovFit <- eBayes(fit2)
# extract unique IDs for each peptides
peptide_tags <- rownames(PhosProtGel)
# compute FDR of the F-test p-values
fdr_vals <- p.adjust(GelPrepCovFit$F.p.value, method = "fdr")
names(fdr_vals) <- peptide_tags
# extract FDR values < .05
sig_fdr_vals <- fdr_vals[which(fdr_vals < .05)]
# mark the least signifiant peptides (according to FDR)
marker_peptide <- names(which.max(sig_fdr_vals))
#' Simulate single peptide
#'
#' Simulate expression for a single peptide using
#' parameters estimated for the selected significant peptide
#'
#' @param I Number of individuals
#' @param J Number of culture replicates
#' @param K Number of techncial replicates per culture replicate
#' @param s2_post Posterior estimate of residual error variance
#' @param phi Correlation between culture replicates (data-wide mean estimated using limma)
fake_peptide <- function(I = 3, J, K, s2_post, phi,
mu_list) {
person <- rep(seq(0, (I-1)), each = J*K)
culture <- rep(rep(1:J, each = K), I)
tech <- rep(1:K, I*J)
# make covariance matrix (for each person)
# our model assuming that the variance-covariance between peptides
# is the same for all three individuals
cormatrix <- diag(rep(phi, len = J), nrow = J,
ncol = J) %x% array(1, c(K, K))
diag(cormatrix) <- 1
varmatrix <- s2_post*cormatrix
require(MASS)
y <- c(mvrnorm(n = 1, mu = rep(mu_list[1], J*K), Sigma = varmatrix),
mvrnorm(n = 1, mu = rep(mu_list[2], J*K), Sigma = varmatrix),
mvrnorm(n = 1, mu = rep(mu_list[3], J*K), Sigma = varmatrix))
return(data.frame(y = y,
person = person,
culture = culture,
tech = tech))
}
#' Compute power
#'
#' Use limma function to compute power
#'
#' @param n_sims Number of simulation
#' @param s2_post residual variance
#' @param phi correlation between culture replicates (within the same batch)
#' @param cov_vector sample protein expression levels for the selected peptide
power_peptide <- function(n_sims, alpha,
I, J, K, s2_post, phi,
mu_list,
cov_vector) {
## Simulate expression data
y_single <- fake_peptide(I, J, K, s2_post, phi, mu_list)
design <- y_single[,-1]
y_matrix <- y_single$y
repeat{
y <- fake_peptide(I, J, K,
s2_post, phi,
mu_list)$y
y_matrix <- rbind(y_matrix,y)
if (nrow(y_matrix) == n_sims) break
}
## Make Protein data covariate matrix
cov_matrix <- matrix( rep(cov_vector, each = J*K, times = n_sims),
ncol = I*J*K, nrow = n_sims,
byrow = TRUE)
## fit limma approach of significant testing
## note that we do not use voom weights here
fit <- gls.series_multiple_designs(
M = y_matrix,
cov_matrix = cov_matrix,
design = model.matrix(~ as.factor(design$person)),
ndups = 1,
spacing = 1,
block = as.factor(design$culture),
correlation = phi)
tstat <- with(fit, coefficients[,1:I]/stdev.unscaled[1:I]/sigma)
tstat_df <- fit$df.residual
tstat_pval <- 2 * pt(abs(tstat), tstat_df, lower.tail = FALSE)
ntests <- ncol(tstat)
Q <- diag(ntests)/sqrt(ntests)
fstat <- drop((tstat %*% Q)^2 %*% array(1, c(ntests, 1)))
fstat_df1 <- ntests
fstat_df2 <- tstat_df
fstat_pval <- pf(fstat, df1 = fstat_df1, df2 = fstat_df2,
lower.tail = FALSE)
power <- mean(fstat_pval < alpha)
return(power)
}
which_marker_peptide <- which(rownames(coef(GelPrepCovFit)) == marker_peptide)
# extract expression data
PhosProtGel[which_marker_peptide,]
# Compute person-levle expression average
HL18486 <- mean(PhosProtGel[which_marker_peptide,
grep("HL18486",
colnames(PhosProtGel)[1:12]) ])
HL18862 <- mean(PhosProtGel[which_marker_peptide,
grep("HL18862",
colnames(PhosProtGel)[1:12]) ],
na.rm = TRUE)
HL19160 <- mean(PhosProtGel[which_marker_peptide,
grep("HL19160",
colnames(PhosProtGel)[1:12]) ],
na.rm = TRUE)
# extract adjusted residual variance (technical workup)
s2_post <- GelPrepCovFit$s2.post[which_marker_peptide]
# get estimated data-wide correlation between culture replicates
phi <- GelPrepCovFit$correlation
# get protein covariate vector
cov_vector <- unique(randomPhosProtGel[which_marker_peptide,])
# note that the empirical phi value, which is negative,
# results in sigular matrix when the number of biological replicates
# and technical replicates are large
power_analysis <- function(J, K, alpha, n_sims, phi, s2_post, ...) {
power <- power_peptide(
n_sims,
alpha, I = 3, J, K,
s2_post, phi,
mu_list = c(HL18486, HL18862, HL19160),
cov_vector = cov_vector)
return(power)
}
power_tech <- lapply(c(2, 4, 6), function(k) {
foo <- sapply( c(s2_post, s2_post*3, s2_post*5), function(s2) {
power_analysis(J = 2, K = k, alpha = .05,
phi = 0,
s2_post = s2, n_sims = 1000) })
return(foo)
})
power_tech <- do.call(rbind, power_tech)
power_rep_c6_t6
power_rep_c2_t2 <- lapply(c(1, 3, 5), function(s2_times) {
foo <- sapply( c(0.09, 0.25, 0.49), function(phi_choose) {
power_analysis(J = 2, K = 2, alpha = .05,
phi = phi_choose,
s2_post = s2_post*s2_times, n_sims = 1000) })
return(foo)
})
power_rep_c2_t2 <- do.call(rbind, power_rep_c2_t2)
power_rep_c2_t6 <- lapply(c(1, 3, 5), function(s2_times) {
foo <- sapply( c(0.09, 0.25, 0.49), function(phi_choose) {
power_analysis(J = 2, K = 6, alpha = .05,
phi = phi_choose,
s2_post = s2_post*s2_times, n_sims = 1000) })
return(foo)
})
power_rep_c2_t6 <- do.call(rbind, power_rep_c2_t6)
power_rep_c6_t2 <- lapply(c(1, 3, 5), function(s2_times) {
foo <- sapply( c(0.09, 0.25, 0.49), function(phi_choose) {
power_analysis(J = 6, K = 2, alpha = .05,
phi = phi_choose,
s2_post = s2_post*s2_times, n_sims = 1000) })
return(foo)
})
power_rep_c6_t2 <- do.call(rbind, power_rep_c6_t2)
power_rep_c6_t6 <- lapply(c(1, 3, 5), function(s2_times) {
foo <- sapply( c(0.09, 0.25, 0.49), function(phi_choose) {
power_analysis(J = 6, K = 6, alpha = .05,
phi = phi_choose,
s2_post = s2_post*s2_times, n_sims = 1000) })
return(foo)
})
power_rep_c6_t6 <- do.call(rbind, power_rep_c6_t6)
power_rep_c6_t6
matplot(power_rep_c6_t6, axes = F, type="n",
ylim = c(0,1),
ylab = "Power", xlab = "Multiples of observed technical variance",
main = "6 Culture reps. + 6 Technical reps.")
matlines(power_rep_c6_t6, type = "o", pch = 16, lty = c(1,2,3),
col = "black")
axis(1, at = c(1,2,3), labels = paste0(c(1, 3, 5), "X") )
axis(2, at = seq(0,1, .2))
power_rep_c6_t6
par(mfrow=c(2,3))
matplot(power_rep_c2_t2, axes = F, type="n",
ylim = c(0,1),
ylab = "Power", xlab = "Multiples of observed technical variance",
main = "2 Culture reps. + 2 Technical reps.")
matlines(power_rep_c2_t2, type = "o", pch = 16, lty = c(1,2,3),
col = "black")
axis(1, at = c(1,2,3), labels = paste0(c(1, 3, 5), "X") )
axis(2, at = seq(0,1, .2))
matplot(power_rep_c2_t6, axes = F, type="n",
ylim = c(0,1),
ylab = "Power", xlab = "Multiples of observed technical variance",
main = "2 Culture reps. + 6 Technical reps.")
matlines(power_rep_c2_t6, type = "o", pch = 16, lty = c(1,2,3),
col = "black")
axis(1, at = c(1,2,3), labels = paste0(c(1, 3, 5), "X") )
axis(2, at = seq(0,1, .2))
# make legend
matplot(power_rep_c2_t6, axes = F, type="n", ann=F)
legend("topleft", legend = paste(c("phi=.09 (low culture variance)",
"phi=.25 (moderate culture variance)",
"phi=.49 (high culture variance)")),
lty = c(1,2,3), col = "black", cex = .7)
matplot(power_rep_c6_t2, axes = F, type="n",
ylim = c(0,1),
ylab = "Power", xlab = "Multiples of observed technical variance",
main = "6 Culture reps. + 2 Technical reps.")
matlines(power_rep_c6_t2, type = "o", pch = 16, lty = c(1,2,3),
col = "black")
axis(1, at = c(1,2,3), labels = paste0(c(1, 3, 5), "X") )
axis(2, at = seq(0,1, .2))
matplot(power_rep_c6_t6, axes = F, type="n",
ylim = c(0,1),
ylab = "Power", xlab = "Multiples of observed technical variance",
main = "6 Culture reps. + 6 Technical reps.")
matlines(power_rep_c6_t6, type = "o", pch = 16, lty = c(1,2,3),
col = "black")
axis(1, at = c(1,2,3), labels = paste0(c(1, 3, 5), "X") )
axis(2, at = seq(0,1, .2))
power_rep_c6_t6
?t.teset
?t.test
t.test(1:10, y = c(7:20))
a=t.test(1:10, y = c(7:20))
?qt
qt(a$p.value/2)
qt(a$p.value/2, df = a$parameter)
library(ashr)
?ash
beta.ash = ash(betahat, sebetahat)
beta = c(rep(0,100),rnorm(100))
sebetahat = abs(rnorm(200,0,1))
betahat = rnorm(200,beta,sebetahat)
beta.ash = ash(betahat, sebetahat)
a=beta.ash$result
head(a)
c=with(a, cbind(NegativeProb, PositiveProb))
head(c)
c=with(a, cbind(NegativeProb, PositiveProb, lfsr))
head(c)
c=with(a, cbind(1-NegativeProb, 1-PositiveProb, lfsr))
head(c)
library(workflowr)
?wflow_start
getwd()
setwd("Dropbox/GitHub/")
wflow_start(name="cellbench")
wflow_start(directory=".", name="cellbench")
wflow_start(directory="~/Dropbox/GitHub/", name="cellbench")
wflow_start(directory="~/Dropbox/GitHub/cellbench", name="cellbench")
library(dscrutils)
out <- dscquery("benchmark", c("get_data", "get_data.n1", "get_data.n2", "method", "method.p"))
library(dscrutils)
out <- dscquery("benchmark", c("get_data", "get_data.n1", "get_data.n2", "method"))
out <- dscquery("benchmark", c("get_data", "get_data.n1", "get_data.n2", "method"), "method.p"))
library(dscrutils)
out <- dscquery("benchmark", c("get_data", "get_data.n1", "get_data.n2", "method", "method.p"))
getwd()
setwd("~/Dropbox/GitHub/dsc-log-fold-change/")
out <- dscquery("benchmark", c("get_data", "get_data.n1", "get_data.n2", "method", "method.p"))
out.sub <- out[out$get_data=="random_sample" & out$get_data.n1==50,]
res <- vector("list",4)
for (i in 1:nrow(out.sub)) {
print(i)
fl <- readRDS(paste0("benchmark/",
as.character(out.sub$method.p[i]), ".rds"))
res[[i]] <- data.frame(method = as.character(out.sub$method)[i],
n1_n2 = paste0(out.sub$get_data.n1[i],".",
out.sub$get_data.n2[i]),
pval = fl$p,
stringsAsFactors = F)
}
names(res) <- as.character(out.sub$method)
cols <- c("gray50", "forestgreen", "blue", "orange")
par(mfrow=c(2,2))
for (i in 1:length(res)) {
hist(res[[i]]$pval, main="",
xlab = "p-values", ylab = "Frequency",
nclass = 20, col=cols[i])
title(main=names(res)[i])
}
qq <- lapply(1:length(res), function(i) {
qqplot(x=runif(100,0,1), y=res[[i]]$pval, plot.it=F)
})
plot(qq[[1]]$x, qq[[1]]$y, col = "gray50", cex=.7, pch = 16,
xlab = "Uniform(0,1)", ylab = "Empirical distribution",
main = "QQ-plot")
points(qq[[2]]$x, qq[[2]]$y, col = "forestgreen", cex=.7, pch = 16)
points(qq[[2]]$x, qq[[2]]$y, col = "blue", cex=.7, pch = 16)
points(qq[[3]]$x, qq[[3]]$y, col = "orange", cex=.7, pch = 16)
abline(0,1, col = "black")
title("random sample; 50 & 50", outer=TRUE, line=-1)
##### random sampling per gene
out.sub <- out[out$get_data=="random_gene" & out$get_data.n1==50,]
res <- vector("list",4)
for (i in 1:nrow(out.sub)) {
print(i)
fl <- readRDS(paste0("benchmark/",
as.character(out.sub$method.p[i]), ".rds"))
res[[i]] <- data.frame(method = as.character(out.sub$method)[i],
n1_n2 = paste0(out.sub$get_data.n1[i],".",
out.sub$get_data.n2[i]),
pval = fl$p,
stringsAsFactors = F)
}
names(res) <- as.character(out.sub$method)
cols <- c("gray50", "forestgreen", "blue", "orange")
par(mfrow=c(2,2))
for (i in 1:length(res)) {
hist(res[[i]]$pval, main="",
xlab = "p-values", ylab = "Frequency",
nclass = 20, col=cols[i])
title(main=names(res)[i])
}
qq <- lapply(1:length(res), function(i) {
qqplot(x=runif(100,0,1), y=res[[i]]$pval, plot.it=F)
})
plot(qq[[1]]$x, qq[[1]]$y, col = "gray50", cex=.7, pch = 16,
xlab = "Uniform(0,1)", ylab = "Empirical distribution",
main = "QQ-plot")
points(qq[[2]]$x, qq[[2]]$y, col = "forestgreen", cex=.7, pch = 16)
points(qq[[2]]$x, qq[[2]]$y, col = "blue", cex=.7, pch = 16)
points(qq[[3]]$x, qq[[3]]$y, col = "orange", cex=.7, pch = 16)
abline(0,1, col = "black")
title("random gene; 50 & 50", outer=TRUE, line=-1)
